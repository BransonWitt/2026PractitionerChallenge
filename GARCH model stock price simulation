import numpy as np
import pandas as pd
import yfinance as yf
from arch import arch_model
import time

# =============================================================================
# STEP 1: DOWNLOAD AND FIT
# =============================================================================

print("Downloading S&P 500 data...")
data = yf.download("^GSPC", start="2021-01-01", end="2026-02-01")

if isinstance(data.columns, pd.MultiIndex):
    close_prices = data['Close']['^GSPC']
else:
    close_prices = data['Close']

# Percentage returns (same scale as arch fitting)
returns_pct = 100 * np.log(close_prices / close_prices.shift(1)).dropna()

dates = close_prices.index
n_days = len(close_prices)
S0 = float(close_prices.iloc[0])

print(f"Downloaded {n_days:,} trading days")
print(f"Starting price: ${S0:,.2f}")

# Fit GARCH
print("\nFitting GARCH(1,1)-t...")
model = arch_model(returns_pct, vol='Garch', p=1, q=1, dist='normal')  # Use normal for stability
result = model.fit(disp='off')

mu = result.params['mu']
omega = result.params['omega']
alpha = result.params['alpha[1]']
beta = result.params['beta[1]']

print(f"\nFitted Parameters (percentage scale):")
print(f"  μ = {mu:.6f}")
print(f"  ω = {omega:.6f}")
print(f"  α = {alpha:.4f}")
print(f"  β = {beta:.4f}")
print(f"  α + β = {alpha + beta:.4f}")

# Long-run volatility
long_run_var = omega / (1 - alpha - beta)
long_run_vol = np.sqrt(long_run_var * 252)
print(f"  Long-run annualized volatility: {long_run_vol:.2f}%")

# =============================================================================
# STEP 2: SIMULATE IN PERCENTAGE SCALE (matching fitted scale)
# =============================================================================

def simulate_garch_percentage_scale(
    S0: float,
    n_days: int,
    n_scenarios: int,
    mu: float,           # In percentage (e.g., 0.05 means 0.05%)
    omega: float,        # In percentage squared
    alpha: float,
    beta: float,
    var0: float = None,  # Initial variance in %²
    var_max: float = 25.0  # Max daily variance (5% daily vol → 25 var)
) -> np.ndarray:
    """
    GARCH simulation in PERCENTAGE scale (matching arch package output).
    """
    
    print(f"\nSimulating {n_scenarios:,} scenarios × {n_days:,} days...")
    start_time = time.time()
    
    S_paths = np.zeros((n_scenarios, n_days))
    S_paths[:, 0] = S0
    
    # Initial variance (use long-run variance if not specified)
    if var0 is None:
        var0 = omega / (1 - alpha - beta)
    
    var_daily = np.full(n_scenarios, var0)  # In %²
    S_current = np.full(n_scenarios, S0)
    
    for day in range(1, n_days):
        # Normal shocks
        z = np.random.standard_normal(n_scenarios)
        
        # Shock in percentage scale
        sigma_pct = np.sqrt(var_daily)      # In %
        eps_pct = sigma_pct * z             # In %
        
        # Return in percentage, then convert to decimal for price update
        return_pct = mu + eps_pct           # In %
        return_decimal = return_pct / 100   # Convert to decimal
        
        # Update price
        S_current = S_current * np.exp(return_decimal)
        S_paths[:, day] = S_current
        
        # GARCH variance update (in %² scale)
        var_daily = omega + alpha * (eps_pct ** 2) + beta * var_daily
        
        # Variance bound to prevent explosion
        var_daily = np.minimum(var_daily, var_max)
        
        if day % 500 == 0:
            print(f"  Day {day:,}/{n_days:,}")
    
    print(f"  Done in {time.time() - start_time:.1f} seconds")
    return S_paths

# =============================================================================
# STEP 3: RUN SIMULATION
# =============================================================================

n_scenarios = 500

S_paths = simulate_garch_percentage_scale(
    S0=S0,
    n_days=n_days,
    n_scenarios=n_scenarios,
    mu=0.04,
    omega=omega,
    alpha=alpha,
    beta=beta,
    var_max=25.0  # Cap at ~5% daily vol (~80% annual)
)

# =============================================================================
# STEP 4: CHECK RESULTS
# =============================================================================

terminal_prices = S_paths[:, -1]
actual_terminal = float(close_prices.iloc[-1])

print(f"\nTerminal Price Check:")
print(f"  Actual S&P 500:      ${actual_terminal:,.2f}")
print(f"  Simulated mean:      ${np.mean(terminal_prices):,.2f}")
print(f"  Simulated median:    ${np.median(terminal_prices):,.2f}")
print(f"  Simulated min:       ${np.min(terminal_prices):,.2f}")
print(f"  Simulated max:       ${np.max(terminal_prices):,.2f}")
print(f"  5th percentile:      ${np.percentile(terminal_prices, 5):,.2f}")
print(f"  95th percentile:     ${np.percentile(terminal_prices, 95):,.2f}")

# Check for unrealistic paths
unrealistic = np.sum((terminal_prices > 20000) | (terminal_prices < 1000))
print(f"\n  Unrealistic paths:   {unrealistic} / {n_scenarios} ({unrealistic/n_scenarios:.1%})")

# =============================================================================
# STEP 5: CREATE DATAFRAME
# =============================================================================

df = pd.DataFrame({'Date': dates, 'Actual': close_prices.values})
for i in range(n_scenarios):
    df[f'Simulation {i}'] = S_paths[i, :]

df.to_csv('garch_simulations_correct_scale.csv', index=False)
print(f"\nSaved to 'garch_simulations_correct_scale.csv'")

from StockPriceSimulator import simulateStockData

stock = simulateStockData("AAPL", 365, '1d')

stock.plotMonteCarlo(df, 1, compareColumn="Actual")
