import numpy as np
import pandas as pd
from scipy.stats import t as t_dist
import yfinance as yf
import time

# =============================================================================
# STEP 1: DOWNLOAD ACTUAL S&P 500 DATA (5 YEARS)
# =============================================================================

print("Downloading S&P 500 data...")
data = yf.download("^GSPC", start="2021-01-01", end="2026-02-01")

# Handle MultiIndex columns
if isinstance(data.columns, pd.MultiIndex):
    actual_prices = data['Close']['^GSPC']
else:
    actual_prices = data['Close']

dates = actual_prices.index
n_days = len(actual_prices)
S0 = float(actual_prices.iloc[0])

print(f"Downloaded {n_days:,} trading days")
print(f"Date range: {dates[0].strftime('%Y-%m-%d')} to {dates[-1].strftime('%Y-%m-%d')}")
print(f"Starting price (S0): ${S0:,.2f}")

# =============================================================================
# STEP 2: GARCH PARAMETERS (all in DECIMAL form)
# =============================================================================

# Daily parameters (decimal scale)
mu_annual = 0.08                    # 8% annual return
mu_daily = mu_annual / 252          # Daily mean return

sigma0_annual = 0.20                # 20% annualized volatility
var0_daily = (sigma0_annual ** 2) / 252  # Daily variance

# GARCH parameters (fitted to decimal returns)
omega = 0.000001                    # Variance intercept (very small in decimal)
alpha = 0.10                        # ARCH coefficient
beta = 0.89                         # GARCH coefficient (α + β = 0.99)
nu = 5.34                           # t-distribution df

# Verify long-run volatility
long_run_var_daily = omega / (1 - alpha - beta)
long_run_vol_annual = np.sqrt(long_run_var_daily * 252)
print(f"\nGARCH Parameters:")
print(f"  μ (annual): {mu_annual:.1%}")
print(f"  σ₀ (annual): {sigma0_annual:.1%}")
print(f"  α + β = {alpha + beta:.4f}")
print(f"  Long-run annualized volatility: {long_run_vol_annual:.1%}")

# =============================================================================
# STEP 3: DAILY GARCH SIMULATION (DECIMAL SCALE)
# =============================================================================

def simulate_garch_daily(
    S0: float,
    n_days: int,
    n_scenarios: int,
    mu_daily: float,
    omega: float,
    alpha: float,
    beta: float,
    nu: float,
    var0_daily: float
) -> np.ndarray:
    """
    Daily GARCH(1,1)-t simulation in DECIMAL scale.
    """
    
    print(f"\nSimulating {n_scenarios:,} scenarios × {n_days:,} days...")
    start_time = time.time()
    
    S_paths = np.zeros((n_scenarios, n_days))
    S_paths[:, 0] = S0
    
    # Initialize daily variance
    var_daily = np.full(n_scenarios, var0_daily)
    S_current = np.full(n_scenarios, S0)
    
    for day in range(1, n_days):
        # t-distributed shocks
        z = t_dist.rvs(df=nu, size=n_scenarios)
        z = z / np.sqrt(nu / (nu - 2))  # Standardize to unit variance
        
        # Daily shock (in decimal)
        sigma_daily = np.sqrt(var_daily)
        eps = sigma_daily * z
        
        # Daily return (in decimal)
        daily_return = mu_daily + eps
        
        # Update price
        S_current = S_current * np.exp(daily_return)
        S_paths[:, day] = S_current
        
        # GARCH variance update
        var_daily = omega + alpha * (eps ** 2) + beta * var_daily
        
        if day % 500 == 0:
            print(f"  Day {day:,}/{n_days:,}")
    
    print(f"  Done in {time.time() - start_time:.1f} seconds")
    return S_paths

# =============================================================================
# STEP 4: RUN SIMULATION
# =============================================================================

n_scenarios = 1000

S_paths = simulate_garch_daily(
    S0=S0,
    n_days=n_days,
    n_scenarios=n_scenarios,
    mu_daily=mu_daily,
    omega=omega,
    alpha=alpha,
    beta=beta,
    nu=nu,
    var0_daily=var0_daily
)

# =============================================================================
# STEP 5: VERIFY RESULTS ARE REASONABLE
# =============================================================================

terminal_prices = S_paths[:, -1]
actual_terminal = float(actual_prices.iloc[-1])

print(f"\nTerminal Price Check:")
print(f"  Actual S&P 500: ${actual_terminal:,.2f}")
print(f"  Simulated mean: ${np.mean(terminal_prices):,.2f}")
print(f"  Simulated median: ${np.median(terminal_prices):,.2f}")
print(f"  Simulated range: ${np.min(terminal_prices):,.2f} - ${np.max(terminal_prices):,.2f}")
print(f"  5th-95th percentile: ${np.percentile(terminal_prices, 5):,.2f} - ${np.percentile(terminal_prices, 95):,.2f}")

# =============================================================================
# STEP 6: CREATE DATAFRAME
# =============================================================================

print("\nCreating DataFrame...")

df = pd.DataFrame({
    'Date': dates,
    'Actual': actual_prices.values
})

for i in range(n_scenarios):
    df[f'Simulation {i}'] = S_paths[i, :]

print(f"DataFrame shape: {df.shape}")

# Save
df.to_csv('garch_simulations_5yr.csv', index=False)
print("Saved to 'garch_simulations_5yr.csv'")
